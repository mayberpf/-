# YOLO
本文主要记录YOLO的部分关键词，也许不能构成一个详细的讲解，但是可以理解为笔记这样的东西
####非极大值抑制
步骤：首先从所有的检测框中找到置信度最大的那个，然后遍历剩余的框，计算其与最大框之间的iou。如果其值大于一定阈值，则表示重合度过高，那么就将该框剔除，循环执行，直到处理完所有的检测框。
#### YOLOv1
没有anchor这个概念
输出：7 * 7 * （cxywh * 每个网络预测的边框个数 + 类别数）
损失函数：边框损失、置信度损失、类别损失。均使用均方差损失函数（MSE）
不足：
1、对于拥有群体小目标的图片
2、对于新尺寸目标
3、最后一层采用全连接层
4、MSE处理大小边框
#### YOLOv2
Darknet19
使用batch normal
使用anchor
更高分辨率224--->448，以及数据增强
多尺度训练，每迭代10个batch，随机更换尺寸（注：均为32的倍数）
使用pass through？？？
边界框位置预测使用sigmod
#### YOLOv3
Darknet-53
使用残差结构，步长为2的卷积替代池化，全卷积网络
多尺度预测，采用类似FPN融合的方式
大中小三个目标输出
正负样本匹配策略？？
分类器损失采用二分类交叉损失函数BCE代替softmax，原因是：多分类标签
损失函数：
置信度损失-----BCE
类别损失------BCE
定位损失------MSE
只有正样本参与类别损失，定位损失和置信度损失。负样本只参与置信度损失
三个损失之间加入平衡系数
#### YOLOv4
backbone：CSPDarknet53
neck：SPP、PAN
Head：与YOLOv3的检测头一致
Bag of freebies
采用一些方法使模型有更高的准确度但是不增加模型的复杂度和模型的推理代价
Bag of specials
plugin module 或后置方法以些许推理代价的增加换取模型准确率的提升
backbone中的BOF
    cutmix
    mosaic数据增强
    dropblock 正则化累
    标签平滑
backbone中的BOS
    mish激活函数
    CSP结构
    多输入权重残差连接
其他BOF
    CIOU损失
    CmBN
    Cross mini-Batch Normaliztion
    CBN的改进版本
    DropBlock正则化
    Mosaic数据增强
    自对抗（SAT）
    Cosine退火算法
    优化超参数
    训练随机输入图像尺寸
其他BOF
    Mish激活函数
    SPP
    SAM模块将SAM的spatial-wise注意力改为point-wise注意力机制
    PAN路径集成模块 将PAN中的shortcut连接变成了concatenation连接
    DIOU-NMS

#### CSP
优点：
增强CNN的学习能力，使得在轻量化的同时保持准确性
降低计算瓶颈
降低内存成本
#### Mish激活函数
只在backbone中使用
#### Dropblock
Dropout的主要作用是随机使一些特征失活，是缓解过拟合的一种正则化手段。一般作用在全连接层。Dropout在全连接层是可以起到作用的，但是在卷积层上作用并不是很明显。因为卷积层上的特征是空间相关的，并且一般卷积之后都有池化，池化层本身就是对相邻单元起作用。即使有dropout的存在，相关的信息仍能正常传递给下一层
而在dropblock中，是将特征层中的局部区域丢弃掉，而不是某几个特征。当网络失去了某些相关区域的连续特征后，为了继续拟合，那么网络就不得不往不同的方向进行更新，从而减少过拟合的程度。
#### SPP
空间金字塔池化网络，将输入的特征图进行不同尺度的最大池化，再进行多尺度融合，这样就可提高感受野，分离出最显著的上下文特征，并且几乎没有降低网络运行速度。但更重要的作用是可以让任意大小的特征图都能够转换成固定大小的输出。SPP--->全连接
#### FPN+PAN
FPN自顶向下的金字塔，将特征层的宽高进行缩减
PAN自底向上的金字塔，可以恢复特征层的宽高
#### IOU
交并比
#### GIOU
GIOU是IOU的下界，两个框无限重合时，IOU=GIOU=1
GIOU取值[-1,1]。两者无交集时，取-1。
#### IOU总结
IOU_Loss：主要考虑检测框和目标框重叠面积
GIOU_Loss：在IOU的基础上，解决边界框不重合时的问题
DIOU_Loss：在IOU和GIOU的基础上，考虑边界框中心点距离的信息
CIOU：在DIOU的基础上，考虑边界框宽高比的尺度信息
#### Mosaic
数据增强，类似CutMix

