# YOLO
本文主要记录YOLO的部分关键词，也许不能构成一个详细的讲解，但是可以理解为笔记这样的东西
####非极大值抑制
步骤：首先从所有的检测框中找到置信度最大的那个，然后遍历剩余的框，计算其与最大框之间的iou。如果其值大于一定阈值，则表示重合度过高，那么就将该框剔除，循环执行，直到处理完所有的检测框。
#### YOLOv1
没有anchor这个概念
输出：7 * 7 * （cxywh * 每个网络预测的边框个数 + 类别数）
损失函数：边框损失、置信度损失、类别损失。均使用均方差损失函数（MSE）
不足：
1、对于拥有群体小目标的图片
2、对于新尺寸目标
3、最后一层采用全连接层
4、MSE处理大小边框
#### YOLOv2
Darknet19
使用batch normal
使用anchor
更高分辨率224--->448，以及数据增强
多尺度训练，每迭代10个batch，随机更换尺寸（注：均为32的倍数）
使用pass through？？？
边界框位置预测使用sigmod
#### YOLOv3
Darknet-53
使用残差结构，步长为2的卷积替代池化，全卷积网络
多尺度预测，采用类似FPN融合的方式
大中小三个目标输出
正负样本匹配策略？？
分类器损失采用二分类交叉损失函数BCE代替softmax，原因是：多分类标签
损失函数：
置信度损失-----BCE
类别损失------BCE
定位损失------MSE
只有正样本参与类别损失，定位损失和置信度损失。负样本只参与置信度损失
三个损失之间加入平衡系数
#### YOLOv4
backbone：CSPDarknet53
neck：SPP、PAN
Head：与YOLOv3的检测头一致
Bag of freebies
采用一些方法使模型有更高的准确度但是不增加模型的复杂度和模型的推理代价
Bag of specials
plugin module 或后置方法以些许推理代价的增加换取模型准确率的提升
backbone中的BOF
    cutmix
    mosaic数据增强
    dropblock 正则化累
    标签平滑
backbone中的BOS
    mish激活函数
    CSP结构
    多输入权重残差连接
其他BOF
    CIOU损失
    CmBN
    Cross mini-Batch Normaliztion
    CBN的改进版本
    DropBlock正则化
    Mosaic数据增强
    自对抗（SAT）
    Cosine退火算法
    优化超参数
    训练随机输入图像尺寸
其他BOF
    Mish激活函数
    SPP
    SAM模块将SAM的spatial-wise注意力改为point-wise注意力机制
    PAN路径集成模块 将PAN中的shortcut连接变成了concatenation连接
    DIOU-NMS

#### CSP
优点：
增强CNN的学习能力，使得在轻量化的同时保持准确性
降低计算瓶颈
降低内存成本
#### Mish激活函数
只在backbone中使用
#### Dropblock
Dropout的主要作用是随机使一些特征失活，是缓解过拟合的一种正则化手段。一般作用在全连接层。Dropout在全连接层是可以起到作用的，但是在卷积层上作用并不是很明显。因为卷积层上的特征是空间相关的，并且一般卷积之后都有池化，池化层本身就是对相邻单元起作用。即使有dropout的存在，相关的信息仍能正常传递给下一层
而在dropblock中，是将特征层中的局部区域丢弃掉，而不是某几个特征。当网络失去了某些相关区域的连续特征后，为了继续拟合，那么网络就不得不往不同的方向进行更新，从而减少过拟合的程度。
#### SPP
空间金字塔池化网络，将输入的特征图进行不同尺度的最大池化，再进行多尺度融合，这样就可提高感受野，分离出最显著的上下文特征，并且几乎没有降低网络运行速度。但更重要的作用是可以让任意大小的特征图都能够转换成固定大小的输出。SPP--->全连接
#### FPN+PAN
FPN自顶向下的金字塔，将特征层的宽高进行缩减
PAN自底向上的金字塔，可以恢复特征层的宽高
#### IOU
交并比
#### GIOU
GIOU是IOU的下界，两个框无限重合时，IOU=GIOU=1
GIOU取值[-1,1]。两者无交集时，取-1。
#### IOU总结
IOU_Loss：主要考虑检测框和目标框重叠面积
GIOU_Loss：在IOU的基础上，解决边界框不重合时的问题
DIOU_Loss：在IOU和GIOU的基础上，考虑边界框中心点距离的信息
CIOU：在DIOU的基础上，考虑边界框宽高比的尺度信息
#### Mosaic
数据增强，类似CutMix

#### YOLOv5
基本组件包括：CBL(conv+bn+leaky_relu)、CSP{n}_x(CBL+n个残差模块+concat+bn+leaky_relu+conv)、SPP
这里面的SPP做了改进===>SPPF。就是将原本并行的maxpool换成了串行的maxpool。也就是两个5*5的maxpool替代一个9 * 9的maxpool，三个5 * 5的maxpool替代一个13 *13的maxpool。串行和并行的效果是一样的，但是串行的效率要更高。

在YOLOv5中涉及的知识：Mosaic数据增强、自适应锚框计算、自适应图片缩放、自适应图片缩放、Focus结构、CSP结构、FPN+PAN结构、GIOU_Loss
#### 自适应锚框计算
在之前的版本，v3v4针对不同数据集，都会先计算anchor的大小。然后对网络进行训练，并在anchor的基础上进行预测，训练等操作。而这里v5的版本将计算锚框大小的功能嵌入到训练代码中。在每次训练开始之前，都会根据不同的数据来自适应计算anchor。当然这个功能也是可以自己关闭的。
#### 自适应图片缩放
原始缩放存在的问题：许多图片的长宽不同，所以在填充之后，两端的黑边大小都不相同了，如果填充的太多，就会出现冗余信息，从而影响整体的推理速度。YOLOv5提出了一种自适应添加最少的黑边到缩放之后的图片。步骤如下：
1、根据原始图片大小与输入到网络图片大小计算缩放比例
2、根据原始图片大小与缩放比例计算缩放后的图片大小
3、计算黑边填充数值
注：该操作仅在推理阶段，训练阶段和传统方法相同。v3v4填充的默认数值（0，0，0）v5默认填充的数值是（114，114，114）。该操作仅针对短边。长边仍裁剪到416.
#### Focus结构
Focus模块实际上就是将输入通道扩充了4倍，这是在YOLOv5中提出的，作用就是可以使信息不丢失的情况下提高计算力。实际操作就是将特征图进行分块操作，然后再将结果concat起来，再送经过一层CBL。从代码里很明显可以看出来，将输入x(bn,c,h,w)做了四个切片，切片的步长都是2，但是如何解释这样操作会让效果变好，我不太懂。
```r
class Focus(nn.Module):
    # Focus wh information into c-space
    def __init__(self, c1, c2, k=1, s=1, p=None, g=1, act=True):  # ch_in, ch_out, kernel, stride, padding, groups
        super(Focus, self).__init__()
        self.conv = Conv(c1 * 4, c2, k, s, p, g, act)
        # self.contract = Contract(gain=2)
    def forward(self, x):  # x(b,c,w,h) -> y(b,4c,w/2,h/2)
        return self.conv(torch.cat([x[..., ::2, ::2], x[..., 1::2, ::2], x[..., ::2, 1::2], x[..., 1::2, 1::2]], 1))
```
#### CSP结构
在YOLOv5的backbone中使用了CSP{n}_x这里的n代表着这个模块中包含几个残差结构。并且在neck中使用了CSP2_x,加强网络的特征融合能力。
#### NMS非极大值抑制
这里简单整理一下，非极大值抑制的操作流程：
1、对所有预测框的置信度降序排序
2、选出置信度最高的预测框，确认其为正确预测，并计算它与其他预测框的IOU
3、根据步骤2中计算的IOU去除重叠度高的，IOU>threshold阈值就直接删除
4、剩下的预测框返回第一步，直到没有剩下的为止
注：NMS一次处理只会一个类别，所以如果有N个类别，那就继续执行N次
其中--->softNMS为了解决两个目标靠的非常近的时，置信度低的会被高的抑制。思想就是：用稍低一点的分数来代替原有的分数。
#### 训练策略
多尺度训练：如果网络输入是416 *416 那么训练时会从0.5 * 416 到1.5 *416中任意取值，但是所取的值都是32的倍数
训练开始前会使用warmup进行训练，先使用较小的学习率训练一些epoch，再修改为预先设置的学习率进行训练
使用cosine学习率下降策略
采用了EMA更新权重，相当于训练时给参数赋予一个动量，这样更新起来就会更加平滑。
使用了amp进行混合精度训练，能够减少显存的占用并加快训练速度，但需要GPU支持。
#### 损失函数
Location loss====CIOU loss，只计算正样本的定位损失
Classes loss 和 Objectness loss ======BCE loss，其中类别损失也只会计算正样本的分类
Objectness loss是使用所有样本进行反向传播，并且使用的是玩过预测的目标边界框与真实框的CIOU

