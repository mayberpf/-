# 13题
### NMS的原理是什么
### NMS有哪些缺陷
### 如何实现多类NMS
### NMS有哪些改进方法
### 它们的改进思路是什么？

NMS也叫做非极大值抑制，就是在目标检测中，不论是one-stage还是two-stage，都会 产生许多预测框，他们大多都指向同一个目标，因此需要通过极大值抑制来筛选掉多余的框，来找到每个目标最优的预测框。
基本做法：先选择置信度最高的框作为基准，计算其余框与该框的IOU重合度，如果IOU重合度超过阈值，说明这两个框可能是预测的相同的物体，所以就去掉置信度低的，保留高的。重复这个过程直到所有的框的重合度都低于阈值。使用该方法可以大量减少冗余的预测框。

缺陷：
阈值不好确定，阈值低了容易出现漏检，高了容易误检
计算IOU的方式有缺陷，如果两个框没有相交，根据定义，iou=0，不能反应两者之间的距离（例子：大框包小框）

如何实现多类的NMS
每个类别自己的内部做NMS

NMS有那些改进方法？及改进思路

soft-nms：可以不要那么暴力的删除所有IOU大于阈值的框，而是降低其置信度
softer-nms：传统的nms用到的score仅仅是分类置信度得分，不能反应预测框的定位精度，也就是分类置信度和定位置信度非正相关。softer-nms基于soft-nms，对预测标注方差范围内的候选框进行加权平均，使得高定位置信度的预测框具有较高的分类置信度。预测的四个顶点坐标，分别对IOU>Nt的预测加权平均计算，得到新的4个坐标点。？？？
diou-nms：使用diou的方式计算iou。
adaptive-nms：自适应调整nms阈值，当检测目标不密集时，就使用较低的nms阈值，当检测目标密集出现许多重叠时，就是用较高的nms阈值。
weighted-nms：加权非极大值抑制，nms每次迭代所选出的最大得分框未必是精确定位的，冗余框也可能是良好的。weighted-nms与nms相比，就是在过滤矩形框时，不是直接采用IOU大于阈值，且类别相同的方法，而是根据网络预测的置信度进行加权，来得到新的预测矩形框。