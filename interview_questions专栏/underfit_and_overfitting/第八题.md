# 第八题
### 解释以下什么是过拟合、欠拟合？如何判断过拟合、欠拟合？导致过拟合的原因有哪些？导致欠拟合的原因有哪些？有哪些方法避免过拟合？有哪些方法避免欠拟合？
#### 个人见解
首先是我们对拟合的理解，在机器学习中有一个经典的例子，就是有两种颜色的点集，将相同颜色的点划分在一个集合。那么一开始可能划分的不太好，但是随着模型的学习，效果会慢慢好起来，这个划分的过程可以理解为拟合的过程。那么过拟合实际上，就是过度的拟合，也就是模型的过度学习，导致该模型只能针对某一特定的数据进行划分，之前见到过一张图片可以很好的帮助理解过拟合现象
@import "1.png"
所以过拟合会导致模型的泛化性不好，欠拟合应该就是还没有学习到为位。
#### 资料查询
参考：http://t.csdn.cn/FP6dv
过拟合（Overfitting）：就是太过贴近于训练数据的特征了，在训练集上表现非常优秀，近乎完美的预测/区分了所有的数据，但是在新的测试集上却表现平平，不具泛化性，拿到新样本后没有办法去准确的判断。
通过文章中图片的描述：可以看到过拟合有一个显著的特征就是：训练集的loss很低，但是验证集的loss值相对于训练集要高很多。
欠拟合（UnderFitting）：测试样本的特性没有学到，或者是模型过于简单无法拟合或区分样本。
这里我有一个问题就是：欠拟合可不可以理解为不收敛。然后我去查了以下：欠拟合和不收敛是不一样的！！！
欠拟合（under-fitting），是指模型拟合程度不高，数据距离拟合曲线较远，或指模型没有很好地捕捉到数据特征，不能够很好地拟合数据。即，在训练数据集上表现差，在测试集数据也表现差。
不收敛（non-convergence）,指误差函数一直在振荡，不能趋近一个定值，没有找到局部或者全局最小值。
参考：http://t.csdn.cn/4XvpA
##### 解决方法
解决过拟合的方法：增大数据量，正则化（L1,L2），丢弃法Dropout（把其中的一些神经元去掉只用部分神经元去构建神经网络）

解决欠拟合的方法：优化模型，一般是模型过于简单无法描述样本的特性。

