{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DL template\n",
    "我想了很久到底用什么文件去写这个，因为我感觉这个文件会是未来不论是师弟师妹的传承，还是代码的复习都会有很大的帮助。因为这篇文章就像名字一样，我准备将前期学习的pytorch做一个总结，针对不同的模块，规定一个代码的范式，这样后面不论是更改模型，还是复现代码，都会更加的方便。\n",
    "之所以选择使用这个模式的文档，是因为更希望代码和解释能更清楚。我首先会分成几个部分写，最后汇总成一个。\n",
    "以下是在整理代码时，参考的链接(除了在比赛中使用见过的代码)：\n",
    "https://github.com/victoresque/pytorch-template\n",
    "https://github.com/bubbliiiing/yolov7-pytorch\n",
    "在写的途中，我发现很多人都是利用了什么yaml、json等一系列的配置文件，但是我真的个人感觉，这种没有那种，直接写出来的看的舒服。所以我准备了这个模板。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 需要的库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import tqdm\n",
    "import albumentations as A\n",
    "import cv2\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 随机种子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 123\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加载模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):#这里放初始化的参数\n",
    "        super(Model,self).__init__()\n",
    "        pass\n",
    "    def forward(self,x):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'\n",
    "model_path = ''\n",
    "model = Model()\n",
    "###模型初始化###\n",
    "model_dict      = model.state_dict()\n",
    "pretrained_dict = torch.load(model_path, map_location = device)\n",
    "###选择权重添加###\n",
    "model.load_state_dict(model_dict)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据增强"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_transforms(img_size):\n",
    "    data_transforms = {\n",
    "        \"train\": A.Compose([\n",
    "            A.Resize(img_size, interpolation=cv2.INTER_NEAREST),\n",
    "            A.HorizontalFlip(p=0.5),\n",
    "            A.VerticalFlip(p=0.5),\n",
    "            A.RandomRotate90(p=0.5),\n",
    "            A.ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.2, rotate_limit=15, p=0.9, border_mode=cv2.BORDER_REFLECT),\n",
    "            A.OneOf([\n",
    "                A.OpticalDistortion(p=0.3),\n",
    "                A.GridDistortion(p=.1),\n",
    "                # IAAPiecewiseAffine(p=0.3),\n",
    "            ], p=0.3),\n",
    "            A.OneOf([\n",
    "                A.HueSaturationValue(10,15,10),\n",
    "                A.CLAHE(clip_limit=2),\n",
    "                A.RandomBrightnessContrast(),            \n",
    "            ], p=0.3),\n",
    "            ], p=1.0),\n",
    "        \"valid_test\": A.Compose([\n",
    "            A.Resize(img_size, interpolation=cv2.INTER_NEAREST),\n",
    "            ], p=1.0)\n",
    "        }\n",
    "    return data_transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class model_Dataset(nn.Module):\n",
    "    def __init__(self) :#这里存放输入\n",
    "        super().__init__(model_Dataset,self)\n",
    "        ###这里做数据读取的初始化--->得到文件所在目录###\n",
    "        ###数据增强之类的初始化###\n",
    "        pass\n",
    "    def __len__(self):\n",
    "        pass\n",
    "    def __getitem__(self,index):\n",
    "        ###根据序号，提取数据###\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataset_dataloader(data_transforms):\n",
    "    train_dataset = model_Dataset(data_transforms)\n",
    "    val_dataset = model_Dataset(data_transforms)\n",
    "    train_dataloader = DataLoader(train_dataset,batch_size=1,shuffle=True,num_workers=16)\n",
    "    val_dataloader = DataLoader(val_dataset,batch_size=1,shuffle=True,num_workers=16)\n",
    "    return train_dataloader,val_dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 优化器学习率搭建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_lr = 5e-5\n",
    "weight_decay = 5e-4\n",
    "momentum = 0.937\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=init_lr,momentum = momentum, weight_decay=weight_decay) # optimizer\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size = 15, gamma=0.1, last_epoch=-1) \n",
    "###更多的学习率调整策略可以查看torch.optim.lr_scheduler###\n",
    "###也可以通过自己写学习率的调整策略###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 搭建Loss and metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelLoss(nn.Module):\n",
    "    def __init__(self) :#这里放初始化的输入\n",
    "        super().__init__(ModelLoss,self)\n",
    "        #这里是loss的实例化\n",
    "        pass\n",
    "    def __call__(self,):#这里放预测真值等\n",
    "        pass\n",
    "class ModelMetric(nn.Module):\n",
    "    def __init__(self) :#这里放初始化的输入\n",
    "        super().__init__(ModelMetric,self)\n",
    "        #这里是metric的实例化\n",
    "        pass\n",
    "    def __call__(self,):#这里放预测真值等\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_loss    = ModelLoss()\n",
    "model_metric = ModelMetric()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train_one_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp16 = False#这是用来定义半精度训练的\n",
    "if fp16:\n",
    "    from torch.cuda.amp import GradScaler as GradScaler\n",
    "    scaler = GradScaler()\n",
    "else:\n",
    "    scaler = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, train_loader, optimizer, lr_scheduler,device,losses_dict):\n",
    "    model.train()\n",
    "    all_loss = 0\n",
    "    pbar = tqdm(enumerate(train_loader), total=len(train_loader), desc='Train ')\n",
    "    for _, (images, labels) in pbar:\n",
    "        optimizer.zero_grad()\n",
    "        images = images.to(device, dtype=torch.float) \n",
    "        labels  = labels.to(device, dtype=torch.float)  \n",
    "        if not fp16:#不做半精度训练\n",
    "            y_preds = model(images) \n",
    "            loss = losses_dict(y_preds, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            lr_scheduler.step()\n",
    "        else:\n",
    "            from torch.cuda.amp import autocast\n",
    "            with autocast():\n",
    "                outputs         = model(images)\n",
    "                loss      = losses_dict(outputs, labels)\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.step(lr_scheduler)\n",
    "            scaler.update()\n",
    "        all_loss+=loss.item()\n",
    "        ###logger记录整个过程###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## val_one_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_one_epoch(model, val_loader,device,metric):\n",
    "    model.eval()\n",
    "    all_acc = 0\n",
    "    pbar = tqdm(enumerate(val_loader), total=len(val_loader), desc='Val ')\n",
    "    for _, (images, labels) in pbar:\n",
    "        images = images.to(device, dtype=torch.float) \n",
    "        labels  = labels.to(device, dtype=torch.float)  \n",
    "        y_preds = model(images) \n",
    "        acc = metric(y_preds, labels)\n",
    "    all_acc+=acc\n",
    "    return all_acc\n",
    "        ###logger记录整个过程###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    seed = 42 \n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    num_worker = 16 \n",
    "    data_path = \"\"\n",
    "    third_data_path = \"\"\n",
    "    ckpt_path = \"\" \n",
    "    # step2: data\n",
    "    img_size = [512, 512]\n",
    "    train_bs = 8\n",
    "    valid_bs = train_bs * 2\n",
    "    # step3: model\n",
    "    # step4: optimizer\n",
    "    epoch = 50\n",
    "    lr = 1e-4\n",
    "    wd = 1e-5\n",
    "    lr_drop = 30\n",
    "    # step5: infer\n",
    "    thr = 0.3\n",
    "\n",
    "    train_val_flag = True\n",
    "    if train_val_flag:\n",
    "        data_transforms = build_transforms(img_size)  \n",
    "        train_loader, valid_loader = build_dataset_dataloader(data_transforms) # dataset & dtaloader\n",
    "        model.to(device)\n",
    "\n",
    "        best_val_acc = 0\n",
    "        best_epoch = 0\n",
    "        for epoch_now in range(1, epoch+1):\n",
    "            start_time = time.time()\n",
    "            train_one_epoch(model, train_loader, optimizer, lr_scheduler,device,model_loss)\n",
    "            # lr_scheduler.step()\n",
    "            val_acc = val_one_epoch(model, valid_loader,device,model_metric)\n",
    "            ##### >>>>>>> step4: save best model <<<<<<\n",
    "            is_best = (val_acc > best_val_acc)\n",
    "            best_val_acc = max(best_val_acc, val_acc)\n",
    "            if is_best:\n",
    "                save_path = f\"{ckpt_path}/epoch{epoch}_dice{best_val_acc:.4f}.pth\"\n",
    "                if os.path.isfile(save_path):\n",
    "                    os.remove(save_path) \n",
    "                torch.save(model.state_dict(), save_path)\n",
    "            \n",
    "            epoch_time = time.time() - start_time\n",
    "            print(\"epoch:{}, time:{:.2f}s, best:{:.2f}\\n\".format(epoch, epoch_time, best_val_acc), flush=True)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 小记\n",
    "如果说分块写的话，主要的主要就是上面那几部分，但是其实还远远不够，因为很多细节都没有补充，所以下面我会增加一些细节的实现模块。同时这只是一个简单的类似README的文件，我准备在这个文件夹下，建立一个模板项目。"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
