#数据增强
####作用
数据增强的作用
1、避免过拟合----当数据集具有某种明显特征，例如数据集中图片多在统一场景拍摄
2、提升鲁棒性----降低模型对图像的敏感度，如遮挡亮度模糊等
3、增加训练数据，提高模型泛化能力
4、避免样本不均衡
####数据增强的分类
分为两类：
在线增强：在训练时对数据集预处理，不改变数据的数量
离线增强：训练前对数据集使用
我的理解就是离线增强主要用于数据不足时，在线增强用于数据充足时。
####常用方法
比较常使用的几何变换：翻转，旋转，裁剪，缩放，平移，抖动。但是这里我有一个问题，我们都知道在对数据使用这些之后，我们实际上也要对真实值进行相同的操作。如果是普通的mask分割，我可以理解，那么真实值就和原图做相同的操作。但是如果是目标检测类的呢，真实的输出实际上是一个框的whxy，那我要怎样用代码实现真实值的变换呢？
比较常用的像素变换方法有：加椒盐噪声，高斯噪声，进行高斯模糊，调整hsv对比度，调节亮度，饱和度，直方图均衡化，调整白平衡等
#####cutout
做法：对一张图随即选取一个小正方形区域，在这个区域的像素值设置为0或其他统一的值。注：存在50%的概率不对图像使用cutout
代码参考：https://github.com/uoguelph-mlrg/Cutout
```r
import torch
import numpy as np
class Cutout(object):
    """Randomly mask out one or more patches from an image.
    Args:
        n_holes (int): Number of patches to cut out of each image.
        length (int): The length (in pixels) of each square patch.
    """
    def __init__(self, n_holes, length):
        self.n_holes = n_holes
        self.length = length

    def __call__(self, img):
        """
        Args:
            img (Tensor): Tensor image of size (C, H, W).
        Returns:
            Tensor: Image with n_holes of dimension length x length cut out of it.
        """
        h = img.size(1)
        w = img.size(2)
        mask = np.ones((h, w), np.float32)
        for n in range(self.n_holes):
            y = np.random.randint(h)
            x = np.random.randint(w)
            y1 = np.clip(y - self.length // 2, 0, h)
            y2 = np.clip(y + self.length // 2, 0, h)
            x1 = np.clip(x - self.length // 2, 0, w)
            x2 = np.clip(x + self.length // 2, 0, w)
            mask[y1: y2, x1: x2] = 0.
        mask = torch.from_numpy(mask)
        mask = mask.expand_as(img)
        img = img * mask
        return img
```
#####random erasing
这个算法实际上和cutout差不多，但是与cutout不同的是random erasing的掩码区域采用的长宽，并且区域中的像素值都是随即的。cutout是正方形遮挡，并且区域内像素统一
官方代码：https://github.com/zhunzhong07/Random-Erasing
```r
class RandomErasing(object):
    def __init__(self, EPSILON = 0.5, sl = 0.02, sh = 0.4, r1 = 0.3, mean=[0.4914, 0.4822, 0.4465]):
        self.EPSILON = EPSILON
        self.mean = mean
        self.sl = sl
        self.sh = sh
        self.r1 = r1
       
    def __call__(self, img):

        if random.uniform(0, 1) > self.EPSILON:
            return img

        for attempt in range(100):
            area = img.size()[1] * img.size()[2]
       
            target_area = random.uniform(self.sl, self.sh) * area
            aspect_ratio = random.uniform(self.r1, 1/self.r1)

            h = int(round(math.sqrt(target_area * aspect_ratio)))
            w = int(round(math.sqrt(target_area / aspect_ratio)))

            if w < img.size()[2] and h < img.size()[1]:
                x1 = random.randint(0, img.size()[1] - h)
                y1 = random.randint(0, img.size()[2] - w)
                if img.size()[0] == 3:
                    #img[0, x1:x1+h, y1:y1+w] = random.uniform(0, 1)
                    #img[1, x1:x1+h, y1:y1+w] = random.uniform(0, 1)
                    #img[2, x1:x1+h, y1:y1+w] = random.uniform(0, 1)
                    img[0, x1:x1+h, y1:y1+w] = self.mean[0]
                    img[1, x1:x1+h, y1:y1+w] = self.mean[1]
                    img[2, x1:x1+h, y1:y1+w] = self.mean[2]
                    #img[:, x1:x1+h, y1:y1+w] = torch.from_numpy(np.random.rand(3, h, w))
                else:
                    img[0, x1:x1+h, y1:y1+w] = self.mean[1]
                    # img[0, x1:x1+h, y1:y1+w] = torch.from_numpy(np.random.rand(1, h, w))
                return img

        return img
```
#####mixup
主要思想是在数据集中随即选择两种图片按照一定的比例融合，包括标签值。
```r
for (x1,y1) , (x2,y2) in zip(load1,load2):
    lam = numpy.random.beta(alpha,alpha)
    x = Variable(lam*x1+(1.-lam)*x2)
    y = Variable(lam*y1+(1.-lam)*y2)
    optimizer.zero_grid()
    loss(net(x),y).backward()
    optimizer.step()
```
代码参考：https://github.com/facebookresearch/mixup-cifar10
#####hide-and-seek
将图片分为s*s的网格，每个网格有一定概论进行掩码。论文中阐述掩码所使用的像素值对识别会有影响，经过计算，采用图像的像素均值的影响最小
代码参考：https://github.com/kkanshul/Hide-and-Seek
#####cutmix
该方法结合了cutout、erasing、mixup三者的思想，选择一个区域做掩码，但是掩码的方式是选择另一张图片的该区域覆盖到这里。
代码参考：https://github.com/clovaai/CutMix-PyTorch
#####gridmask
前面说的几种掩码均是随机的，也就是掩码有可能遮住全部重要信息，而gridmask则最多出现部分掩盖，且几乎一定会出现部分掩盖，使用的方法是排列的正方形区域进行掩码。
具体实现是通过设定每个小正方形的边长，两个掩吗之间的距离来确定掩码，从而控制掩码细粒度。
#####fencemask
针对gridmask进行的改进，看图就可以明白一切
@import "1.png"

####多样本数据增强
mosaic---该方法用于yolov4,原理是使用四张图片拼接成一张图片，这样做的好处是图片的背景不再是单一的场景，而是四种不同的场景下，且使用bn时，相当于每一层同时在四张图片上进行归一化，可以大大减少batchsize

####关于解决正负样本不均匀的方法
hard negative example mining, focal loss等
####网络结构的数据增强
在网络模型中我们通常会使用DropOut，DropConnect和DropBlock，这些也可以理解为数据增强。