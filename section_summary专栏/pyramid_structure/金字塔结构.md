#特征金字塔结构
####原因
不同大小的目标都经过了相同的降采样比例后会出现较大的语义代沟，最常见的表现就是小目标检测精度比较低。特征金字塔具有在不同尺度下不同分辨率的特点，不同大小的目标都可以在相应的尺度下拥有和是的特征表示，融合多尺度信息，在不同尺度下对不同大小的目标进行预测，从而很好的提升了模型的特性。
####构建方式
1、降采样生成不同分辨率层
2、通过多条不同空洞率的空洞卷积的支路构建
####ASPP
经过多支路后进行cat+1*1卷积
论文:https://arxiv.org/pdf/1606.00915.pdf
@import "ASPP.png"
关于空洞卷积的初步了解就是：空洞卷积有两种实现形式，卷积核填充0；或者输入间隔
```r
nn.Conv2d(in_dim, out_dim, kernel_size=3, stride=1, padding=2, dilation=2)
#空洞卷积只需要比普通卷积多一个参数dilation
```
####FPN
这里需要放一张经常出现的图片，帮助理解fpn
@import "FPN.png"
在之前，神经网络多数为上图b的形式，图c为SSD模型采用的方式，这种方式的缺点是低层的语义信息不够。图d就是FPN结构，在c的基础上增加了一条自上而下的路径
####PANet
缩短信息流动路径和增加不同分支来增加信息流动路径的思想会产生比较强的性能
我的理解就是在一般神经网络+FPN+自下而上的路径
最终因为分而治之（大目标在金字塔的高层检测，小目标在金字塔的低层检测），但是PANet因为目标相差超过10px时，就可能会分到不同的level检测，实际上这两个差不多，因此PANet将所有的候选框均用来预测，不再划分大目标和小目标。
####RFB
改进ASPP结构
ASPP使用不同空洞率的空洞卷积组成分支结构效果不错，但是因为空洞卷积的卷积核大小相同，但是空洞率不同，因此只会更改特征图的感受野，分辨率不会发生改变。优化：在空洞卷积之前加入一层卷积核不同的卷积。
####ASFF
改进PANet:问题，PANet希望金字塔的不同层输出不同大小的检测结果，高层金字塔预测大目标，低层金字塔预测小目标，但是在不同金字塔层的特征既存在大目标又存在小目标，那么只能将不满足大小的目标当作background，这就会存在很大的问题
因此ASFF将PANet中自下而上的分支和上一层分支进行融合。
####FPT
人脑的思想？电脑只会出现在电脑桌？
####其他金字塔结构
BiFPN
STDN
SFAM
