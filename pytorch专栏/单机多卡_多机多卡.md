# 单机多卡_多机多卡
这部分感觉已经写烂了，因别很多文章都是关于这个，我也是看了很多，但是我真的一直没有使用过。实际上主要是介绍pytorch中的DP和DDP，在本篇文章中还介绍了多机多卡的另一种方式：通过horovod库。
# 单机单卡
这个实际上就是我现在使用的配置，也就是正常设置，不需要通过torch.nn.DataParallel将模型置于不同的GPU中。这就是一个最简单的模型训练框架。确认GPU，然后读取数据、模型、优化器，然后进行epoch迭代，从DataLoader中读取数据，放进模型进行计算，得到损失函数，进行反向传播。
```ruby
import torch
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
train_dataset = ...
train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=...)
model = ...
optimizer = optim.SGD(model.parameters())
for epoch in range(opt.num_epoch):
    for i, (input, target) in enumerate(train_loader):
        input= input.to(device)
        target = target.to(device)
        ...
        output = model(input)
        loss = criterion(output, target)
        ...
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
```
# 单机多卡训练
这部分，还是使用两个方法，DP和DDP两个方法。
DP的方法，比较简单，仅仅是将网络进行处理即可
```ruby
model = nn.DataParallel(model.to(device), device_ids=None, output_device=None)
```
其中device_ids主要是设置使用哪些GPU，device_ids=None，表示使用所有GPU，当然也可以动手设置使用哪些
```ruby
gpus = [0, 1, 2, 3]
torch.cuda.set_device('cuda:{}'.format(gpus[0]))
model = nn.DataParallel(model.to(device), device_ids=None,
output_device=gpus[0])
```
这里DDP会比DP要复杂的多了，这里就只贴出代码，不详细解释了。
```ruby
import torch
import argparse
import torch.distributed as dist
parser = argparse.ArgumentParser()
parser.add_argument('--local_rank', default=-1, type=int,
help='node rank for distributed training')
opt = parser.parse_args()
# 初始化GPU通信方式(NCCL)和参数的获取方式(env代表通过环境变量)。
dist.init_process_group(backend='nccl', init_method='env://')
torch.cuda.set_device(opt.local_rank)
train_dataset = ...
train_sampler =
torch.utils.data.distributed.DistributedSampler(train_dataset)
train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=...,
sampler=train_sampler)
# 使用 DistributedDataParallel 包装模型,它能帮助我们为不同 GPU 上求得的梯度进行
all reduce(即汇总不同 GPU 计算所得的梯度,并同步计算结果)。all reduce 后不同 GPU
中模型的梯度均为 all reduce 之前各 GPU 梯度的均值。
model = ...
model = torch.nn.parallel.DistributedDataParallel(model, device_ids=
[args.local_rank])
optimizer = optim.SGD(model.parameters())
for epoch in range(opt.num_epoch):
    for i, (input, target) in enumerate(train_loader):
        input= input.cuda()
        target = target.cuda()
        ...output = model(input)
        loss = criterion(output, target)
        ...
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
#运行命令
CUDA_VISIBLE_DEVICES=0,1,2,3 python -m torch.distributed.launch --
nproc_per_node=4 train.py
```