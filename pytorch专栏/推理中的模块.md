# 推理中各个模块
## 数据读取
推理实际上就是在模型训练完成之后，将想要检测的文件放进模型，最后得到检测结果的过程。
数据读取主要分为一下几个方法，单张图片、摄像头获取、多张图片。其中多张图片就和验证环节基本没什么差别了，也就是dataset，dataloader进行读取就好了。
### 单张图片
这个方法实际上很简单，甚至连dataset都不需要，直接读取图片进行预测即可。下面的代码是使用的PIL.Image读取的图片，也可以通过其他的库，比如opencv。
```ruby
import torch
from PIL import Image
import torchvision.transforms as transforms
def image_proprecess(img_path):
    img = Image.open(img_path)
    data_transforms = transforms.Compose([
        # transforms.Resize((384, 384), interpolation=3),
        transforms.ToTensor(),
        # transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
        ])
    data = data_transforms(img)
    data = torch.unsqueeze(data,0)
    return img, data
```
代码中主要负责执行的是：读取图片，通过PIL.Image读取的图片是PIL的格式。。。这里不是我挑刺，我感觉PIL读取图片之后，我们还需要一步将其转换为numpy的形式才能继续做transforms。所以我去跑了一下代码，确实有错误，但是并不是我说的那个错误，而是维度的问题。详细的问题可以自己看下，只需要把代码中那两行注释掉就好了。
这部分主要是学习如何调用摄像头读取数据，并且我这里也有一个工业相机，最近也在看关于这个摄像头的标定等问题，未来会写一个关于相机标定的总结文档。
```ruby
import cv2
cap = cv2.VideoCapture(0)
#cap = cv2.VideoCapture("data/monitor.mp4") #读取视频width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
fps = cap.get(cv2.CAP_PROP_FPS)
#这是为了保存视频,先提前进行的配置
fourcc = cv2.VideoWriter_fourcc('m','p','4','v')
out = cv2.VideoWriter('data/detected_monitor.mp4',fourcc,fps,(width,height))
if not cap.isOpened():
    print("Unable to open camera")
    exit(-1)
#配置图像预处理过程
data_transforms = transforms.Compose([
    transforms.Resize((384, 384), interpolation=3),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ])
while True:
    res, img = cap.read()
    if res:
        data = data_transforms(img)
        data = torch.unsqueeze(data,0)
        #下面是推理过程,
        pred = inference(data)
        #以目标检测为例,后处理,从pred中读出预测框,这里省略
        bboxes = ...
        #在img原图上画框,并保存
        draw_img = plot_boxes_cv2(img, bboxes, None, class_names)
        out_img = cv2.resize(draw_img,(width,height))
        out.write(out_img)#保存视频
```
问题是，这个工业相机好像不能随便就用opencv就调用吧。因为实际上是有一个驱动的。

## 推理
在加载了数据之后呢，直接进行推理就行了。和验证时基本没差别
```ruby
from model import Yolo_v1
def inference():
    img_path = "dog.png"
    img, data = image_proprecess(img_path)
    data = torch.autograd.Variable(data.cuda())
    net = Yolo_v1()
    net.load_state_dict(torch.load(trained_path))
    net = net.cuda().eval()
    pred = net(data)
    #以目标检测为例,后处理,从pred中读出预测框,这里省略
    bboxes = ...
    #在img原图上画框,并保存
    draw_img = plot_boxes_cv2(img, bboxes, None, class_names)
    out_img = cv2.resize(draw_img,(width,height))
```