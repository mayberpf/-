# 参数量
统计参数量可以使用
```ruby
param.numel()
```
整体函数如下：
```ruby
def get_parameter_number(model):
    total_num = sum(p.numel() for p in model.parameters())
    trainable_num = sum(p.numel() for p in model.parameters() if p.requires_grad)
    return {'Total': str(total_num / 1000 ** 2) + 'M', 'Trainable':str(trainable_num / 1000 ** 2) + 'M'}
print(get_parameter_number(net))
```
参数量也可以使用thop的profile进行统计
```ruby
from thop import profile
from torchvision.models.resnet import resnet50
import torch
dummy_input = torch.rand(1, 3, 224, 224).cpu()
net = resnet50(num_classes=99, pretrained=False).cpu()
flops, params = profile(net, inputs=(dummy_input, ))
print("-" * 50)
print('FLOPS =' + str(flops / 1000 ** 3) + 'G')
print('Params =' + str(params / 1000 ** 2) + 'M')
```
# 查看模型结构
这部分是重点，这里不经常使用，但是却是我们了解模型、更改模型最基础的事情
```model.state_dict()```查看模型字典
```model.modules()```这个函数会返回一个生成器，是一个可迭代的变量，遍历模型的所有子层
```model.children()```只会遍历模型的第一层子层。
```model.parameters()```迭代返回模型的所有参数
```model.named_modules()、model.named_children()、model.named_parameters()```不仅返回模型子层，还会带上名字

## 科普
参数量的科普
就简单说下：
FLOPS：指的是每秒浮点运算次数，可以理解为计算速度是一个衡量硬件性能的指标。
FLOPs：浮点运算数，可以理解为计算量，用来衡量模型的复杂度。
