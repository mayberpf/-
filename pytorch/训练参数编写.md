# 训练参数的编写
首先我们要搞清楚训练过程中有哪些参数是我们需要定义的。训练过程主要是指train.py文件，其中包括参数的解析，训练日志的配置，设置随机数种子，classdataset的初始化，网络的初始化，学习率的设置，损失函数的设置，优化方式的设置，Tensorboard的配置，训练过程的搭建等
那么关于模型的训练参数，包含了：文件保存目录，数据集目录，学习率，epoch数量，模块中的参数等。
那么实际在代码中是如何写入这些参数的呢？首先是我们最常见的argparser的设置，就是在主函数开始之后会有一大段的参数设定。其实一开始我不是很了解，所以感觉就是这样的代码设置好像对初学者不是那么友好。就比如下面这个，我就想问问，一个小白，谁看谁不迷湖。第二种方法呢，就是yaml文件进行设置，那么问题就又来了，代码是怎么读取的，这对一个小白确实也不是那么友好，反正我是深受其嘲讽。仿佛代码在跟我说：我这么美，你竟然看不懂。
```ruby
if __name__ == '__main__':
    parser = argparse.ArgumentParser()
    parser.add_argument('--weights', type=str, default='', help='initial weights path')#初始的权重文件，default一般为空的
    parser.add_argument('--cfg', type=str, default='models/yolov5s.yaml', help='model.yaml path')#模型的配置
    parser.add_argument('--data', type=str, default='data/mydata2.yaml', help='data.yaml path')#指定训练集
    parser.add_argument('--hyp', type=str, default='data/hyp.scratch.yaml', help='hyperparameters path')#训练的超参数
    parser.add_argument('--epochs', type=int, default=50)#训练的轮次
    parser.add_argument('--batchsize', type=int, default=16, help='total batch size for all GPUs')#batch文件，把数据打包成batch送到网络当中（涉及原理上的东西）根据显存进行修改
    parser.add_argument('--img-size', nargs='+', type=int, default=[640, 640], help='[train, test] images sizes')#图片的尺寸
    parser.add_argument('--rect', action='store_true', help='rectangular training')#矩阵的训练方式
    parser.add_argument('--resume', nargs='?', const=True, default=False, help='resume most recent training')#从一个文件中指定一个文件开始训练，继续训练
    parser.add_argument('--nosave', action='store_true', help='only save final checkpoint')#只保存最后的一个权重数据
    parser.add_argument('--notest', action='store_true', help='only test final epoch')#是不是在最后一个点进行测试
    parser.add_argument('--noautoanchor', action='store_true', help='disable autoanchor check')#锚点框和没有锚点框的区别（文献看一下区别）
    parser.add_argument('--evolve', action='store_true', help='evolve hyperparameters')#参数的进化，寻找最优的参数
    parser.add_argument('--bucket', type=str, default='', help='gsutil bucket')#最常见的bucket文件
    parser.add_argument('--cache-images', action='store_true', help='cache images for faster training')#需不需要缓存一个图片
    parser.add_argument('--image-weights', action='store_true', help='use weighted images selection for training')#图片的权重
    parser.add_argument('--device', default='', help='cuda device, i.e. 0 or 0,1,2,3 or cpu')#指定cuda的cpu的配置文件
    parser.add_argument('--multi-scale', action='store_true', help='vary img-size +/- 50%%')#图像的加减变换，保证能被32整除
    parser.add_argument('--single-cls', action='store_true', help='train multi-class data as single-class')#单类别还是多类别的文件，默认是多类别的文件
    parser.add_argument('--adam', action='store_true', help='use torch.optim.Adam() optimizer')#优化器
    parser.add_argument('--sync-bn', action='store_true', help='use SyncBatchNorm, only available in DDP mode')#ddp的分布式训练
    parser.add_argument('--local_rank', type=int, default=-1, help='DDP parameter, do not modify')#多个GPU进行训练修改参数
    parser.add_argument('--workers', type=int, default=1, help='maximum number of dataloader workers')#修改进程，default修改进程
    parser.add_argument('--project', default='runs/train', help='save to project/name')#运行之后保存的位置
    parser.add_argument('--entity', default=None, help='W&B entity')#库的标识，可视化训练进程
    parser.add_argument('--name', default='exp', help='save to project/name')
    parser.add_argument('--exist-ok', action='store_true', help='existing project/name ok, do not increment')
    parser.add_argument('--quad', action='store_true', help='quad dataloader')
    parser.add_argument('--linear-lr', action='store_true', help='linear LR')
    parser.add_argument('--label-smoothing', type=float, default=0.0, help='Label smoothing epsilon')
    parser.add_argument('--upload_dataset', action='store_true', help='Upload dataset as W&B artifact table')
    parser.add_argument('--bbox_interval', type=int, default=-1, help='Set bounding-box images logging interval for W&B')
    parser.add_argument('--save_period', type=int, default=-1, help='Log model after every "save_period" epoch')
    parser.add_argument('--artifact_alias', type=str, default="latest", help='version of dataset artifact to be used')
    opt = parser.parse_args()
```
好了我们言归正传。
# yaml
首先我们先针对yaml文件说吧。
了解一下yaml文件的语法规则
```ruby
#大小写敏感
#使用缩进表示层级关系
#缩进时不允许使用Tab键，只允许使用空格(可以将ide的tab键设置为4的空格键)
#缩进的空格数目不重要，只要相同层级的元素左侧对齐即可
#使用#表示注释
```
接下来我们说一下关于yaml文件的解析示例：
说白了就是使用代码读取yaml文件,读取完发现实际上就是一个字典。
```ruby
import yaml
import os

curPath = os.path.dirname(os.path.realpath(__file__))
# 获取yaml文件路径
yamlPath = os.path.join(curPath, "cfgyaml.yaml")
 
# open方法打开直接读出来
f = open(yamlPath, 'r', encoding='utf-8')
cfg = f.read()
print(type(cfg))  # 读出来是字符串
print(cfg)
 
d = yaml.load(cfg)  # 用load方法转字典
print(d)
print(type(d))
```
# argparser
argparser解析的形式一般放在train.py的最前面。其实也可以单独搞一个util.py。
代码的示例就和文章一开始一样。
使用方法：python train.py --batchsize 16 --epoch 50
访问元素: 在所有参数设置完之后，会有```    opt = parser.parse_args()```此时所有的参数就存在了opt中，我们就可以通过它和键的名字进行调用了。例如```print(opt.batchsize)```
