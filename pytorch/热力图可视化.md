# 热力图可视化
首先清楚热力图的作用：在神经网络模型中，图片经过神经网络得到类别输出，我们并不知道是根据什么来做出预测的，换言之我们需要了解到图片中各个区域对模型做出预测有多大影响。这就是热力图。通过得到图像不同区域之间对模型的重要性而生成一张类似于等温图的图片。
热力图可视化，经过CAM，GradCAM到GradCAM++的过程，最常用的是GradCAM
CAM的原理是取出全连接层中得到类别C的概率的那一维权值，用w表示。然后对GAP前的feature map 进行加权求和，由于此时feature map不是原图大小，在加权求和后还需要进行上采样，即可得到class activation map
但是在CAM中，其结构是CNN+GAP+FC+Softmax组成。也就是想要可视化某个模型，需要对GAP的模型来说需要修改原模型结构，并重新训练，相当麻烦，且模型如果很大，对修改后重新训练模型不一定能达到原来的效果，可视化就没有意义了。
因此后续出现了改进版GradCAM
## GradCAM
同样是处理CNN特征提取网络的最后一层feature maps。Grad-CAM对于想要可视化的类别C,使最后输出的类别C的概率值通过反向传播到最后一层feature maps,得到类别C对该feature maps的每个像素的梯度值,对每个像素的梯度值取全局平均池化,即可得到对feature maps的加权系数alpha,论文中提到这样获取的加权系数跟CAM中的系数的计算量几乎是等价的。接下来对特征图加权求和,使用ReLU进行修正,再进行上采样。
### 使用
代码原链接:https://github.com/jacobgil/pytorch-grad-cam/tree/master/pytorch_grad_cam
本教程代码链接:https://github.com/CV-Tech-Guide/Visualize-feature-maps-and-heatmap
代码使用很简单，只需要简单的调用就好了
```ruby
if __name__ == "__main__":
    imgs_path = "path/to/image.png"
    model = models.mobilenet_v3_large(pretrained=True)
    model.load_state_dict(torch.load('model.pth'))
    model = model.cuda().eval()
    #target_layers指的是需要可视化的层,这里可视化最后一层
    target_layers = [model.features[-1]]
    img, data = image_proprecess(imgs_path)
    data = data.cuda()
    cam = GradCAM(model=model, target_layers=target_layers)
    #指定可视化的类别,指定为None,则按照当前预测的最大概率的类作为可视化类。
    target_category = None
    grayscale_cam = cam(input_tensor=data, target_category=target_category)
    grayscale_cam = grayscale_cam[0, :]
    visualization = show_cam_on_image(np.array(img) / 255., grayscale_cam)
    plt.imshow(visualization)
    plt.xticks()
    plt.yticks()
    plt.axis('off')
    plt.savefig("path/to/gradcam_image.jpg")
```

这里讲解的只适用于分类任务的热力图可视化，那么对于目标检测，语义分割这些包含多任务的应用应该怎么做呢？
那就需要详细看下GradCAM这个作者是怎么做的？在他的GitHub中也写了教程
https://github.com/jacobgil/pytorch-grad-cam